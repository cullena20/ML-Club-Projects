{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HousingPrices.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "-cXhTxm6KgNL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        " \n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NVKtSGQDLTQ1",
        "colab_type": "code",
        "outputId": "5bcc786e-c4c6-4e13-c5ee-71ed99abd7d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Enter the ID of the Google Drive folder containing train.csv and test.csv files.\n",
        "# The ID of the folder is the long string of numbers and letters in the URL of the folder in Google Drive.\n",
        "\n",
        "file_list = drive.ListFile({'q': \"'1V76PUZB9NA-kWRJmJdDGbtnCidNWpT9C' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s' % (file1['title'], file1['id']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: HousingPrices.ipynb, id: 1Bi7AmvHdffrqgVLjBNCdHtSbPYzT44Wp\n",
            "title: train (1), id: 1_2k3JMa33JeuO29WjNq8Tvz15ySqG1sVUUQmEQCM6yg\n",
            "title: test (1).csv, id: 12g-Ro232gNbmTHKW9z3_fFDKrLpEJRTQ\n",
            "title: train (1).csv, id: 1ygU2lQVVRTE1x_kMXD7MCNb1q7irc2ts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mU9CO_k6Lo_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Enter the ID of train.csv and test.csv. The IDs are printed in the output of the cell above.\n",
        "train_downloaded = drive.CreateFile({'id': '1ygU2lQVVRTE1x_kMXD7MCNb1q7irc2ts'})\n",
        "train_downloaded.GetContentFile('train.csv')\n",
        "test_downloaded = drive.CreateFile({'id': '12g-Ro232gNbmTHKW9z3_fFDKrLpEJRTQ'})\n",
        "test_downloaded.GetContentFile('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFdiZX5-LwUw",
        "colab_type": "code",
        "outputId": "1c3e9454-9c13-454d-bb35-daed03464ef7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# See the top rows of the train.csv file\n",
        "!ls\n",
        "!head train.csv\n",
        "!head test.csv\n",
        "#!wc -l train.csv\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json\t\t training_examples11.tfr  training_examples5.tfr\n",
            "model_dir\t\t training_examples12.tfr  training_examples6.tfr\n",
            "sample_data\t\t training_examples13.tfr  training_examples7.tfr\n",
            "test.csv\t\t training_examples1.tfr   training_examples8.tfr\n",
            "train.csv\t\t training_examples2.tfr   training_examples9.tfr\n",
            "training_examples0.tfr\t training_examples3.tfr\n",
            "training_examples10.tfr  training_examples4.tfr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K-c1l0xiMDYI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import pandas, which is the library for the data structures being used\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from dateutil import parser\n",
        "import datetime\n",
        "from datetime import date\n",
        "import math\n",
        "\n",
        "# Load train.csv into pandas dataframe and print the summary\n",
        "df = pd.read_csv('train.csv')\n",
        "df1 = pd.read_csv('test.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62Ap1UW-MCvM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Show shapes of the data\n",
        "print (\"Train data shape:\", df.shape)\n",
        "print (\"Test data shape:\", df1.shape)\n",
        "print list(df)\n",
        "print list(df1)\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from dateutil import parser\n",
        "import datetime\n",
        "from datetime import date\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "def get_features(row):\n",
        "  complete = True\n",
        "  SalePrice = row['SalePrice']\n",
        "  OverallQual = row['OverallQual']\n",
        "  OverallCond = row['OverallCond']\n",
        "  YearBuilt = row['YearBuilt']\n",
        "  FullBath = row['FullBath']\n",
        "  BedroomAbvGr = row['BedroomAbvGr']\n",
        "  HalfBath = row['HalfBath']\n",
        "  LotArea = row['LotArea']\n",
        "  GrLivArea = row['GrLivArea']\n",
        "  Neighborhood = row['Neighborhood']\n",
        "  if math.isnan(SalePrice) \\\n",
        "    or math.isnan(OverallQual) \\\n",
        "    or math.isnan(OverallCond) \\\n",
        "    or math.isnan(YearBuilt) \\\n",
        "    or math.isnan(FullBath) \\\n",
        "    or math.isnan(BedroomAbvGr):\n",
        "    complete = False\n",
        "  features = {\n",
        "      \"SalePrice\": tf.train.Feature(float_list = tf.train.FloatList(value=[math.log(SalePrice)])),\n",
        "      \"OverallQual\": tf.train.Feature(float_list = tf.train.FloatList(value=[OverallQual])),\n",
        "      \"OverallCond\": tf.train.Feature(float_list = tf.train.FloatList(value=[OverallCond])),\n",
        "      \"YearBuilt\": tf.train.Feature(float_list = tf.train.FloatList(value=[(YearBuilt - 1990.) / 10.])),\n",
        "      \"FullBath\": tf.train.Feature(float_list = tf.train.FloatList(value=[FullBath])),\n",
        "      \"BedroomAbvGr\": tf.train.Feature(float_list = tf.train.FloatList(value=[BedroomAbvGr])),\n",
        "      \"HalfBath\": tf.train.Feature(float_list = tf.train.FloatList(value=[HalfBath])),\n",
        "      \"LotArea\": tf.train.Feature(float_list = tf.train.FloatList(value=[LotArea / 1000.0])),\n",
        "      \"GrLivArea\": tf.train.Feature(float_list = tf.train.FloatList(value=[GrLivArea / 1000.0])),\n",
        "      \"Neighborhood\": tf.train.Feature(bytes_list = tf.train.BytesList(value=[Neighborhood.encode(\"utf8\")])),\n",
        "  }\n",
        "  return (features, complete)\n",
        "\n",
        "reader = pd.read_csv('train.csv', iterator=True)\n",
        "counter = 0\n",
        "for j in range(14):\n",
        "  tfr_file = (\"training_examples%d.tfr\" % j)\n",
        "  print (\"generating TFRecord file \" + tfr_file)\n",
        "  writer = tf.python_io.TFRecordWriter(tfr_file)\n",
        "\n",
        "  # For int features:\n",
        "  # 'name': tf.train.Feature(int64_list = tf.train.Int64List(value = ...))\n",
        "  # For float features:\n",
        "  # 'name': tf.train.Feature(float_list = tf.train.FloatList(value = ...))\n",
        "\n",
        "  for i in range(10):\n",
        "    print (\"processing chunk #\" + str(i))\n",
        "    df = reader.get_chunk(10)\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "      feature = get_features(row)\n",
        "      if feature[1]:\n",
        "        counter=counter+1\n",
        "        example = tf.train.Example(\n",
        "            features=tf.train.Features(feature=feature[0]))\n",
        "        writer.write(example.SerializeToString())\n",
        "        #print example\n",
        "\n",
        "  writer.close()\n",
        "print(counter)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "auU0FZojn3TF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dx4bJmMTZjZs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feature_columns = [\n",
        "    tf.feature_column.numeric_column('OverallQual', shape=(1,), dtype=tf.float32),\n",
        "    tf.feature_column.numeric_column('OverallCond', shape=(1,), dtype=tf.float32),\n",
        "    tf.feature_column.numeric_column('YearBuilt', shape=(1,), dtype=tf.float32),\n",
        "    tf.feature_column.numeric_column('FullBath', shape=(1,), dtype=tf.float32),\n",
        "    tf.feature_column.numeric_column('BedroomAbvGr', shape=(1,), dtype=tf.float32),\n",
        "    tf.feature_column.numeric_column('HalfBath', shape=(1,), dtype=tf.float32),\n",
        "    tf.feature_column.numeric_column('LotArea', shape=(1,), dtype=tf.float32),\n",
        "    tf.feature_column.numeric_column('GrLivArea', shape=(1,), dtype=tf.float32),\n",
        "    tf.feature_column.embedding_column(\n",
        "        tf.feature_column.categorical_column_with_hash_bucket(\n",
        "        'Neighborhood', hash_bucket_size=1000),\n",
        "        dimension=1)\n",
        "]\n",
        "print(feature_columns)\n",
        "label_column = tf.feature_column.numeric_column('SalePrice', shape=(1,), dtype=tf.float32)\n",
        "\n",
        "features_spec = tf.feature_column.make_parse_example_spec(\n",
        "    feature_columns + [label_column]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JLu_q52i1x4k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn(file_list):\n",
        "  dataset = tf.contrib.data.make_batched_features_dataset(\n",
        "      file_pattern=file_list,\n",
        "      batch_size=100,\n",
        "      features=features_spec,\n",
        "      num_epochs=100,\n",
        "      shuffle=True,\n",
        "      shuffle_buffer_size=10\n",
        "  )\n",
        "  it = dataset.make_one_shot_iterator()\n",
        "  features = it.get_next()\n",
        "  labels = features.pop('SalePrice')\n",
        "  return features, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LuHYKWEY3oyf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -r model_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uvx42QM_12jv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_dir=\"model_dir\"\n",
        "\n",
        "regressor = tf.estimator.DNNRegressor(\n",
        "    hidden_units=[3],\n",
        "    feature_columns=feature_columns,\n",
        "    model_dir=model_dir\n",
        ")\n",
        "\n",
        "def get_eval_metrics(labels, predictions):\n",
        "    print(\"hi\")\n",
        "    print(tf.metrics.root_mean_squared_error(\n",
        "        labels=labels,\n",
        "        predictions=predictions['predictions']\n",
        "    ))\n",
        "    return {\n",
        "      'rmse': tf.metrics.root_mean_squared_error(\n",
        "          labels=labels,\n",
        "          predictions=predictions['predictions']\n",
        "      )\n",
        "  }\n",
        "\n",
        "regressor = tf.contrib.estimator.add_metrics(regressor, get_eval_metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vEX83n2816wX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_spec = tf.estimator.TrainSpec(\n",
        "    input_fn=lambda: input_fn([\n",
        "        'training_examples1.tfr',\n",
        "        'training_examples2.tfr',\n",
        "        'training_examples3.tfr',\n",
        "        'training_examples4.tfr',\n",
        "        'training_examples5.tfr',\n",
        "        'training_examples16tfr',\n",
        "        'training_examples7.tfr',\n",
        "        'training_examples8.tfr',\n",
        "        'training_examples9.tfr',\n",
        "        'training_examples10.tfr']), #,'training_examples2.tfr','training_examples3.tfr','training_examples4.tfr','training_examples5.tfr','training_examples6.tfr','training_examples7.tfr','training_examples8.tfr','training_examples9.tfr']),\n",
        "    max_steps=1000000\n",
        ")\n",
        "\n",
        "# For evaluation, don't shuffle, and read evaluation data just once.\n",
        "def eval_input_fn(file_list):\n",
        "  dataset = tf.contrib.data.make_batched_features_dataset(\n",
        "      file_pattern=file_list,\n",
        "      batch_size=100,\n",
        "      features=features_spec,\n",
        "      num_epochs=1,\n",
        "      shuffle=False\n",
        "      #shuffle_buffer_size=10\n",
        "  )\n",
        "  it = dataset.make_one_shot_iterator()\n",
        "  features = it.get_next()\n",
        "  labels = features.pop('SalePrice')\n",
        "  return features, labels\n",
        "\n",
        "eval_spec = tf.estimator.EvalSpec(\n",
        "    input_fn=lambda: eval_input_fn([\n",
        "        'training_examples0.tfr', \n",
        "        'training_examples11.tfr',\n",
        "        'training_examples12.tfr',\n",
        "        'training_examples13.tfr'])\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S4lpmnJRqch7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "\n",
        "while counter < 50:\n",
        "  tf.estimator.train_and_evaluate(regressor, train_spec, eval_spec)\n",
        "  counter = counter + 1\n",
        "  print(counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rCOJbHbK1_Sr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "variable_names = regressor.get_variable_names()\n",
        "print (\"variable names: \")\n",
        "for var_name in variable_names:\n",
        "  values = regressor.get_variable_value(var_name)\n",
        "  print (var_name, values)\n",
        "\n",
        "\n",
        "def get_test_features(row):\n",
        "  \n",
        "  OverallQual = row['OverallQual']\n",
        "  OverallCond = row['OverallCond']\n",
        "  YearBuilt = row['YearBuilt']\n",
        "  FullBath = row['FullBath']\n",
        "  BedroomAbvGr = row['BedroomAbvGr']\n",
        "  HalfBath = row['HalfBath']\n",
        "  LotArea = row['LotArea']\n",
        "  GrLivArea = row['GrLivArea']\n",
        "  Neighborhood = row['Neighborhood']\n",
        "\n",
        "  features = {\n",
        "      \"OverallQual\": tf.train.Feature(float_list = tf.train.FloatList(value=[OverallQual])),\n",
        "      \"OverallCond\": tf.train.Feature(float_list = tf.train.FloatList(value=[OverallCond])),\n",
        "      \"YearBuilt\": tf.train.Feature(float_list = tf.train.FloatList(value=[(YearBuilt - 1990) / 10])),\n",
        "      \"FullBath\": tf.train.Feature(float_list = tf.train.FloatList(value=[FullBath])),\n",
        "      \"BedroomAbvGr\": tf.train.Feature(float_list = tf.train.FloatList(value=[BedroomAbvGr])),\n",
        "      \"HalfBath\": tf.train.Feature(float_list = tf.train.FloatList(value=[HalfBath])),\n",
        "      \"LotArea\": tf.train.Feature(float_list = tf.train.FloatList(value=[LotArea / 1000.0])),\n",
        "      \"GrLivArea\": tf.train.Feature(float_list = tf.train.FloatList(value=[GrLivArea / 1000.0])),\n",
        "      \"Neighborhood\": tf.train.Feature(bytes_list = tf.train.BytesList(value=[Neighborhood.encode(\"utf8\")])),\n",
        "  }\n",
        "  return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3yEu4fAY2JTx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import math\n",
        "\n",
        "reader = pd.read_csv('test.csv', iterator = True)\n",
        "testdf = reader.get_chunk(1459)\n",
        "\n",
        "\n",
        "testdf['YearBuilt'] = (testdf['YearBuilt'] - 1990) / 10.0\n",
        "testdf['LotArea'] = testdf['LotArea'] / 1000.\n",
        "testdf['GrLivArea'] = testdf['GrLivArea'] / 1000.\n",
        "\n",
        "for index, row in testdf.iterrows():\n",
        "  OverallQual = row['OverallQual']\n",
        "  OverallCond = row['OverallCond']\n",
        "  YearBuilt = row['YearBuilt']\n",
        "  FullBath = row['FullBath']\n",
        "  BedroomAbvGr = row['BedroomAbvGr']\n",
        "  HalfBath = row['HalfBath']\n",
        "  LotArea = row['LotArea']\n",
        "  GrLivArea = row['GrLivArea']\n",
        "  Neighborhood = row['Neighborhood']\n",
        "  if math.isnan(OverallQual):\n",
        "    row['OverallQual'] = 5\n",
        "  if math.isnan(OverallCond):\n",
        "    row['OverallCond'] = 5\n",
        "  if math.isnan(YearBuilt):\n",
        "    row['YearBuilt'] = 0\n",
        "  if math.isnan(FullBath):\n",
        "    row['FullBath'] = 2\n",
        "  if math.isnan(BedroomAbvGr):\n",
        "    row['BedroomAbvGr'] = 2\n",
        "    \n",
        "def eval_input_fn1():\n",
        "  eval_dataset1 = tf.data.Dataset.from_tensor_slices((dict(reader)))\n",
        "  #eval_dataset1 = eval_dataset1.shuffle(batch_size).repeat().batch(batch_size)\n",
        "  eval_dataset1 = eval_dataset1.batch(len(reader))\n",
        "  return eval_dataset1\n",
        "\n",
        "def test_input_fn(df):\n",
        "  x = {\n",
        "      'OverallQual':tf.constant(\n",
        "      df['OverallQual'].values,\n",
        "          shape = [df['OverallQual'].size,1],\n",
        "          dtype=tf.float32),\n",
        "      'OverallCond':tf.constant(\n",
        "      df['OverallCond'].values,\n",
        "          shape = [df['OverallCond'].size,1],\n",
        "          dtype=tf.float32),\n",
        "      'YearBuilt':tf.constant(\n",
        "      df['YearBuilt'].values,\n",
        "          shape = [df['YearBuilt'].size,1],\n",
        "          dtype=tf.float32),\n",
        "      'FullBath':tf.constant(\n",
        "      df['FullBath'].values,\n",
        "          shape = [df['FullBath'].size,1],\n",
        "          dtype=tf.float32),\n",
        "      'BedroomAbvGr':tf.constant(\n",
        "      df['BedroomAbvGr'].values,\n",
        "          shape = [df['BedroomAbvGr'].size,1],\n",
        "          dtype=tf.float32),\n",
        "      'HalfBath':tf.constant(\n",
        "      df['HalfBath'].values,\n",
        "          shape = [df['HalfBath'].size,1],\n",
        "          dtype=tf.float32),\n",
        "      'LotArea':tf.constant(\n",
        "      df['LotArea'].values,\n",
        "          shape = [df['LotArea'].size,1],\n",
        "          dtype=tf.float32),\n",
        "      'GrLivArea':tf.constant(\n",
        "      df['GrLivArea'].values,\n",
        "          shape = [df['GrLivArea'].size,1],\n",
        "          dtype=tf.float32),\n",
        "      'Neighborhood':tf.constant(\n",
        "      df['Neighborhood'].values,\n",
        "          shape = [df['Neighborhood'].size,1],\n",
        "          dtype=tf.string)\n",
        "  }\n",
        "  return x\n",
        "\n",
        "def test_fn_predictions():\n",
        "  return test_input_fn(testdf)\n",
        "\n",
        "# For int features:\n",
        "# 'name': tf.train.Feature(int64_list = tf.train.Int64List(value = ...))\n",
        "# For float features:\n",
        "# 'name': tf.train.Feature(float_list = tf.train.FloatList(value = ...))\n",
        "\n",
        "predictions_generator = regressor.predict(\n",
        "    input_fn=test_fn_predictions,\n",
        "    yield_single_examples=True)\n",
        "\n",
        "iter = itertools.islice(predictions_generator, 1459)\n",
        "\n",
        "predictions = [y['predictions'][0] for y in iter]\n",
        "\n",
        "print len(predictions), \"predictions:\"\n",
        "print predictions\n",
        "\n",
        "predictions = [math.exp(i) for i in predictions]\n",
        "submission = [[\"Id\", \"SalePrice\"]]\n",
        "for i in range(1459):\n",
        "  submission.append([testdf['Id'][i], predictions[i]])\n",
        "print submission\n",
        "\n",
        "#   # Print the prediction results.\n",
        "# print(\"\\nPrediction results:\")\n",
        "# print predict_results\n",
        "# print next(predict_results)\n",
        "# for i, prediction in enumerate(predict_results):\n",
        "#   print prediction"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}